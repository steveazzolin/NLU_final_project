{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c2f63a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=nlu_sentiment_analysis\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/steve/.netrc\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=nlu_sentiment_analysis\n",
    "!wandb login 2cad8a8279143c69ce071f54bf37c1f5a5f4e5ff\n",
    "import wandb\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import requests, re, string, datetime, copy\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T, torch.nn.functional as F, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback, TrainerCallback\n",
    "from transformers import Trainer, get_linear_schedule_with_warmup\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, f1_score\n",
    "\n",
    "\n",
    "PATH = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f12392e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtwitter</th>\n",
       "      <th>subj</th>\n",
       "      <th>opos</th>\n",
       "      <th>oneg</th>\n",
       "      <th>iro</th>\n",
       "      <th>lpos</th>\n",
       "      <th>lneg</th>\n",
       "      <th>top</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122449983151669248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Intanto la partita per Via Nazionale si compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125485104863780865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125513454315507712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125524238290522113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125527933224886272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n",
       "0  122449983151669248     1     0     1    0     0     1    1   \n",
       "1  125485104863780865     1     0     1    0     0     1    1   \n",
       "2  125513454315507712     1     0     1    0     0     1    1   \n",
       "3  125524238290522113     1     0     1    0     0     1    1   \n",
       "4  125527933224886272     1     0     1    0     0     1    1   \n",
       "\n",
       "                                                text  \n",
       "0  Intanto la partita per Via Nazionale si compli...  \n",
       "1  False illusioni, sgradevoli realtà Mario Monti...  \n",
       "2  False illusioni, sgradevoli realtà #editoriale...  \n",
       "3  Mario Monti: Berlusconi risparmi all'Italia il...  \n",
       "4  Mario Monti: Berlusconi risparmi all'Italia il...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH + \"Sentipolc16/training_set_sentipolc16.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734d9bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtwitter</th>\n",
       "      <th>subj</th>\n",
       "      <th>opos</th>\n",
       "      <th>oneg</th>\n",
       "      <th>iro</th>\n",
       "      <th>lpos</th>\n",
       "      <th>lneg</th>\n",
       "      <th>top</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>507074506880712705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Tra 5 minuti presentazione piano scuola del g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>507075789456961536</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\"\\\"@matteorenzi: Alle 10 appuntamento su http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>507077511902425088</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>\"#labuonascuola gli #evangelisti #digitali non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507079183315787777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Riforma scuola Tutto il discorso di  Renzi su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>507080190225563648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>\".@matteorenzi @MiurSocial #labuonascuola bast...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n",
       "0  507074506880712705     0     0     0    0     0     0    2   \n",
       "1  507075789456961536     1     1     0    0     1     0    2   \n",
       "2  507077511902425088     1     0     1    0     0     1    2   \n",
       "3  507079183315787777     0     0     0    0     0     0    2   \n",
       "4  507080190225563648     1     0     0    0     0     0    2   \n",
       "\n",
       "                                                text  \n",
       "0  \"Tra 5 minuti presentazione piano scuola del g...  \n",
       "1  \"\\\"@matteorenzi: Alle 10 appuntamento su http:...  \n",
       "2  \"#labuonascuola gli #evangelisti #digitali non...  \n",
       "3  \"Riforma scuola Tutto il discorso di  Renzi su...  \n",
       "4  \".@matteorenzi @MiurSocial #labuonascuola bast...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = open(PATH + \"Sentipolc16/test_set_sentipolc16_gold2000.csv\", 'r') \n",
    "Lines = file1.readlines()\n",
    " \n",
    "test = []\n",
    "for line in Lines:\n",
    "  arr = line.split(\"\\\",\")\n",
    "  if len(arr) != 9:\n",
    "    arr[8] = arr[8] + arr[9]  #to account for tweets containing the delimiter charachter that would create more splits than needed\n",
    "    del arr[9:]\n",
    "  for i in range(8):\n",
    "    arr[i] = int(arr[i].strip(\"\\\"\"))\n",
    "  test.append(arr)\n",
    "\n",
    "test = pd.DataFrame(test, columns=train.columns)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54754535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tokenization classes for Italian AlBERTo models.\"\"\"\n",
    "import collections\n",
    "import os\n",
    "\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "    \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "    vocab = collections.OrderedDict()\n",
    "    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n",
    "        tokens = reader.readlines()\n",
    "    for index, token in enumerate(tokens):\n",
    "        token = token.rstrip(\"\\n\")\n",
    "        vocab[token] = index\n",
    "    return vocab\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'user', 'percent', 'money', 'phone', 'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "\n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "\n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "class AlBERTo_Preprocessing(object):\n",
    "    def __init__(self, do_lower_case=True, **kwargs):\n",
    "        self.do_lower_case = do_lower_case\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        if self.do_lower_case:\n",
    "            text = text.lower()\n",
    "        text = str(\" \".join(text_processor.pre_process_doc(text)))\n",
    "        text = re.sub(r'[^a-zA-ZÀ-ú</>!?♥♡\\s\\U00010000-\\U0010ffff]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
    "        text = re.sub(r'^\\s', '', text)\n",
    "        text = re.sub(r'\\s$', '', text)\n",
    "        return text\n",
    "\n",
    "a = AlBERTo_Preprocessing(do_lower_case=True)\n",
    "s = \"#IlGOverno presenta le linee guida sulla scuola #labuonascuola - http://t.co/SYS1T9QmQN\"\n",
    "b = a.preprocess(s)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a01b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    sa = tok(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    return sa\n",
    "\n",
    "a = AlBERTo_Preprocessing(do_lower_case=True)\n",
    "s: str = \"#IlGOverno presenta le linee guida sulla scuola #labuonascuola - http://t.co/SYS1T9QmQN\"\n",
    "b = a.preprocess(s)\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
    "pretrained_model = AutoModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
    "tok.model_max_length = 128 #model.config.max_position_embeddings\n",
    "tokens = tok.tokenize(b)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetMC(nn.Module):\n",
    "    \"\"\"\n",
    "        Attach a FC layer on top of the BERT head in order to produce a classification output.\n",
    "\n",
    "        The pooled_output output of BERT is basically a projection of the [CLS] embeddings via another FC layer (768 -> 768 hidden units).\n",
    "        We stack another FC layer with Dropout on top of that, as reported in https://github.com/google-research/bert/blob/eedf5716ce1268e56f0a50264a88cafad334ac61/run_classifier.py#L574\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels):\n",
    "        super(MyNetMC, self).__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.model = copy.deepcopy(pretrained_model)#AutoModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.linear1 = nn.Linear(768, 3)\n",
    "\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def forward(self, labels, input_ids, attention_mask, **args):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, **args)\n",
    "        x = self.dropout1(outputs[1])\n",
    "        logits = self.linear1(x)\n",
    "        loss = self.loss_fct(logits, labels)\n",
    "        return logits , loss\n",
    "    \n",
    "class MyNetMCTuned(nn.Module):\n",
    "    \"\"\"\n",
    "        Attach a FC layer on top of the BERT head in order to produce a classification output.\n",
    "\n",
    "        The pooled_output output of BERT is basically a projection of the [CLS] embeddings via another FC layer (768 -> 768 hidden units).\n",
    "        We stack another FC layer without Dropout on top of that, as reported in https://github.com/google-research/bert/blob/eedf5716ce1268e56f0a50264a88cafad334ac61/run_classifier.py#L574\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels):\n",
    "        super(MyNetMCTuned, self).__init__()\n",
    "\n",
    "        self.num_labels = num_labels\n",
    "        self.model = copy.deepcopy(pretrained_model)\n",
    "        self.linear1 = nn.Linear(768, 3)\n",
    "\n",
    "        self.loss_fct = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, labels, input_ids, attention_mask, **args):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask, **args)\n",
    "        logits = self.linear(outputs[1])\n",
    "        loss = self.loss_fct(logits, labels)\n",
    "        return logits , loss\n",
    "    \n",
    "class EarlyStopping():    \n",
    "    def __init__(self, min_delta = 0, patience = 0):        \n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best = -np.Inf\n",
    "        self.stop_training = False\n",
    "    \n",
    "    def on_epoch_end(self, epoch, current_value):\n",
    "        if np.greater((current_value - self.min_delta), self.best):\n",
    "            self.best = current_value\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait > self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.stop_training = True\n",
    "        return self.stop_training\n",
    "\n",
    "\n",
    "TRAIN_BATCH_SIZE = 64 \n",
    "PREDICT_BATCH_SIZE = 64\n",
    "EVAL_BATCH_SIZE = 64 \n",
    "WEIGHT_DECAY = 0.01\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "MAX_SEQ_LENGTH = 128\n",
    "WARMUP_PROPORTION = 0.1\n",
    "num_train_steps = int(len(training) / TRAIN_BATCH_SIZE * NUM_EPOCHS)+1\n",
    "NUM_WARMUP_STEPS =  int(num_train_steps * WARMUP_PROPORTION)\n",
    "RUN_NAME = \"test_trainer\"\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28651925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, optimizer, scheduler, epoch, logging):\n",
    "    model.train()\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    cumulative_loss = 0.\n",
    "    for i , data in tqdm(enumerate(train_loader, 0), total=len(train_loader)):        \n",
    "        targets.extend(data[\"labels\"].numpy())\n",
    "        \n",
    "        batch = {k: v.to(device) for k, v in data.items()}\n",
    "        logits , loss = model(**batch)\n",
    "\n",
    "        cumulative_loss += loss.detach()\n",
    "        if (i+1) % 25 == 0 and logging:\n",
    "            print(f'Epoch: {epoch}, Loss:  {cumulative_loss.item()/i}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        outputs.extend(logits.argmax(-1).cpu().detach().numpy().tolist())\n",
    "    if logging: wandb.log({\"train\": {'loss': cumulative_loss.item() / len(outputs)}})\n",
    "    return outputs, targets\n",
    "    \n",
    "        \n",
    "def validation_epoch(model, epoch, val_loader, kind, logging):\n",
    "    model.eval()\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    cumulative_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(val_loader, 0):\n",
    "            batch = {k: v.to(device) for k, v in data.items()}\n",
    "            logits , loss = model(**batch)\n",
    "            cumulative_loss += loss.detach()\n",
    "            if (i+1) % 25 == 0 and logging:\n",
    "                print(f'Epoch: {epoch}, Loss:  {cumulative_loss.item()/i}')\n",
    "            \n",
    "            targets.extend(batch[\"labels\"].cpu().detach().numpy())\n",
    "            outputs.extend(logits.argmax(-1).cpu().detach().numpy().tolist())\n",
    "    if logging: wandb.log({kind: {'loss': cumulative_loss.item() / len(outputs)}})\n",
    "    return outputs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04de4d3",
   "metadata": {},
   "source": [
    "# SENTIPOLC16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e871196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idtwitter</th>\n",
       "      <th>subj</th>\n",
       "      <th>opos</th>\n",
       "      <th>oneg</th>\n",
       "      <th>iro</th>\n",
       "      <th>lpos</th>\n",
       "      <th>lneg</th>\n",
       "      <th>top</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122449983151669248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Intanto la partita per Via Nazionale si compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125485104863780865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False illusioni, sgradevoli realtà Mario Monti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>125513454315507712</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False illusioni, sgradevoli realtà #editoriale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125524238290522113</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125527933224886272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mario Monti: Berlusconi risparmi all'Italia il...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idtwitter  subj  opos  oneg  iro  lpos  lneg  top  \\\n",
       "0  122449983151669248     1     0     1    0     0     1    1   \n",
       "1  125485104863780865     1     0     1    0     0     1    1   \n",
       "2  125513454315507712     1     0     1    0     0     1    1   \n",
       "3  125524238290522113     1     0     1    0     0     1    1   \n",
       "4  125527933224886272     1     0     1    0     0     1    1   \n",
       "\n",
       "                                                text  \n",
       "0  Intanto la partita per Via Nazionale si compli...  \n",
       "1  False illusioni, sgradevoli realtà Mario Monti...  \n",
       "2  False illusioni, sgradevoli realtà #editoriale...  \n",
       "3  Mario Monti: Berlusconi risparmi all'Italia il...  \n",
       "4  Mario Monti: Berlusconi risparmi all'Italia il...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe39d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER Adoro questa canzone, è una delle mie pr...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#MilanNovara È  arrivato il 3 gol del MILAN ❤🖤...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stream icarus falls 🖤 zayn ha un talento ed è ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Persona di indiscutibile cultura #Daverio avev...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oggi la direttrice @USER ha spiegato che #COVI...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    label\n",
       "0  @USER Adoro questa canzone, è una delle mie pr...      joy\n",
       "1  #MilanNovara È  arrivato il 3 gol del MILAN ❤🖤...      joy\n",
       "2  stream icarus falls 🖤 zayn ha un talento ed è ...  sadness\n",
       "3  Persona di indiscutibile cultura #Daverio avev...  sadness\n",
       "4  Oggi la direttrice @USER ha spiegato che #COVI...     fear"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH + \"Feel-it/feelit.tsv\", sep='\\t', header=0, names=[\"text\", \"label\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6d02b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'sadness', 'fear', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2label(row):\n",
    "    \"\"\"\n",
    "        Return a single scalar integer label associated to the emotion of the tweet.\n",
    "\n",
    "        joy -> 0\n",
    "        anger  -> 1\n",
    "        sadness -> 2\n",
    "        fear    -> 3\n",
    "    \"\"\"\n",
    "    elif row[\"label\"] == \"joy\":\n",
    "        return 0\n",
    "    elif row[\"label\"] == \"sadness\":\n",
    "        return 2\n",
    "    elif row[\"label\"] == \"fear\":\n",
    "        return 3\n",
    "    elif row[\"label\"] == \"anger\":\n",
    "        return 1\n",
    "\n",
    "#train set\n",
    "dataset = pd.DataFrame({\"text\": train.text.apply(a.preprocess), \"idx\": train.index, \"labels\": train[[\"opos\", \"oneg\"]].apply(separate2united_labels, axis=1)})\n",
    "X_train, X_val = train_test_split(dataset, test_size=0.2, random_state=42, stratify=dataset[\"labels\"])\n",
    "\n",
    "X_train = Dataset.from_pandas(X_train)\n",
    "X_val = Dataset.from_pandas(X_val)\n",
    "\n",
    "training = X_train\\\n",
    "                    .map(tokenize_function, batched=True)\\\n",
    "                    .filter(lambda example: example['labels'] != 3)\\\n",
    "                    .shuffle(seed=42)\\\n",
    "                    .with_format(\"torch\")\n",
    "validating = X_val\\\n",
    "                    .map(tokenize_function, batched=True)\\\n",
    "                    .filter(lambda example: example['labels'] != 3)\\\n",
    "                    .with_format(\"torch\")\n",
    "\n",
    "\n",
    "#test set\n",
    "dataset = pd.DataFrame({\"text\": test.text.apply(a.preprocess), \"idx\": test.index, \"labels\": test[[\"opos\", \"oneg\"]].apply(separate2united_labels, axis=1)})\n",
    "dataset = Dataset.from_pandas(dataset)\n",
    "\n",
    "testing = dataset\\\n",
    "                    .map(tokenize_function, batched=True)\\\n",
    "                    .filter(lambda example: example['labels'] != 3)\\\n",
    "                    .with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6061b17d",
   "metadata": {},
   "source": [
    "### AlBERTo pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(testing.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\", \"token_type_ids\"]), batch_size=64)\n",
    "preds , trues = validation_epoch(model, None, test_loader, \"test\", logging=False)\n",
    "\n",
    "dataset_test = pd.DataFrame({\"text\": test.text.apply(a.preprocess), \"idx\": test.index, \"labels\": test[[\"opos\", \"oneg\"]].apply(separate2united_labels, axis=1)})\n",
    "dataset_test = dataset_test[dataset_test.labels != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cdf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load best model's params\n",
    "model = MyNetMCTuned(3).to(device)\n",
    "model.load_state_dict(torch.load(\"data/models/alberto_multiclass.pt\"))\n",
    "\n",
    "preds , trues = validation_epoch(model, None, test_loader, \"test\", logging=False)\n",
    "\n",
    "for n , (i , row) in enumerate(dataset_test.iterrows()):\n",
    "    if preds[n] != trues[n]:\n",
    "        print(f\"{row['text']} ------ true={row['labels']} pred={preds[n]}  \\n\")\n",
    "        assert row['labels'] == trues[n]\n",
    "        \n",
    "print(classification_report(trues, preds, target_names=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "cm = confusion_matrix(trues, preds, normalize=True)\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"negative\", \"neutral\", \"positive\"]).plot(values_format=\"d\")\n",
    "plt.title(\"Sentipolc16 - AlBERToMC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb519f7",
   "metadata": {},
   "source": [
    "### AlBERTo fine-tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25db4c73",
   "metadata": {},
   "source": [
    "# FEEL-IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e1b22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8df350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
